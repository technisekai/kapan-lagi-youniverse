{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install \n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338c5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "data_dir = \"data\"\n",
    "list_data = [\n",
    "    {\n",
    "        'url': 'https://drive.usercontent.google.com/u/0/uc?id=1uynxymjHuqunDjLeT1FqSfVDFC-jWyXx&export=download', \n",
    "        'filename': 'cms_articles.csv'\n",
    "    },\n",
    "    {\n",
    "        'url': 'https://drive.usercontent.google.com/u/0/uc?id=1ava925zhJFtxlzfvo7CnBiieLH2u0r0-&export=download', \n",
    "        'filename': 'ga4_events.csv'\n",
    "    },\n",
    "    {\n",
    "        'url': 'https://drive.usercontent.google.com/u/0/uc?id=1Dig4PqGiFBRhNTyZsj8Et0AFZ9zJXU2m&export=download', \n",
    "        'filename': 'gam_delivery.csv'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Download the data from Google Drive\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "for data in list_data:\n",
    "    file_path = f\"{data_dir}/{data['filename']}\"\n",
    "    if not os.path.exists(file_path):\n",
    "        urllib.request.urlretrieve(data['url'], f\"{data_dir}/{data['filename']}\")\n",
    "    else:\n",
    "        print(f\"INF skip, {file_path} already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05a2791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials\n",
    "db_creds = {\n",
    "    'hostname': 'localhost',\n",
    "    'port': 5432,\n",
    "    'username': 'admin',\n",
    "    'password': 'admin',\n",
    "    'database': 'public'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635bbfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF creating schema ... [done]\n"
     ]
    }
   ],
   "source": [
    "from scripts.postgresql import (\n",
    "    postgresql_connection,\n",
    "    execute_query\n",
    ")\n",
    "\n",
    "# Creating schemas\n",
    "print(\"INF creating schema ...\", end='')\n",
    "connection = postgresql_connection(\n",
    "    db_creds['hostname'], \n",
    "    db_creds['port'], \n",
    "    db_creds['username'], \n",
    "    db_creds['password'], \n",
    "    db_creds['database']\n",
    ")\n",
    "execute_query(\n",
    "    connection,\n",
    "    \"create schema if not exists bronze; create schema if not exists gold;\"\n",
    ")\n",
    "connection.close()\n",
    "print(' [done]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5deb88a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF partition 2025-09-01\n",
      "INF partition 2025-09-02\n",
      "INF partition 2025-09-03\n",
      "INF partition 2025-09-04\n",
      "INF partition 2025-09-05\n",
      "INF partition 2025-09-06\n",
      "INF partition 2025-09-07\n",
      "INF partition 2025-09-08\n",
      "INF partition 2025-09-09\n",
      "INF partition 2025-09-10\n",
      "INF partition 2025-09-11\n",
      "INF partition 2025-09-12\n",
      "INF partition 2025-09-13\n",
      "INF partition 2025-09-14\n",
      "INF partition 2025-09-15\n",
      "INF partition 2025-09-16\n",
      "INF partition 2025-09-17\n",
      "INF partition 2025-09-18\n",
      "INF partition 2025-09-19\n",
      "INF partition 2025-09-20\n",
      "INF partition 2025-09-21\n",
      "INF partition 2025-09-22\n",
      "INF partition 2025-09-23\n",
      "INF partition 2025-09-24\n",
      "INF partition 2025-09-25\n",
      "INF partition 2025-09-26\n",
      "INF partition 2025-09-27\n",
      "INF partition 2025-09-28\n",
      "INF partition 2025-09-29\n",
      "INF partition 2025-09-30\n",
      "INF partition 2025-10-01\n",
      "INF partition 2025-10-02\n",
      "INF partition 2025-10-03\n",
      "INF partition 2025-10-04\n",
      "INF partition 2025-10-05\n",
      "INF partition 2025-10-06\n",
      "INF partition 2025-10-07\n",
      "INF partition 2025-10-08\n",
      "INF partition 2025-10-09\n",
      "INF partition 2025-10-10\n",
      "INF partition 2025-10-11\n",
      "INF partition 2025-10-12\n",
      "INF partition 2025-10-13\n",
      "INF partition 2025-10-14\n",
      "INF partition 2025-10-15\n",
      "INF partition 2025-10-16\n",
      "INF partition 2025-10-17\n",
      "INF partition 2025-10-18\n",
      "INF partition 2025-10-19\n",
      "INF partition 2025-10-20\n",
      "INF partition 2025-10-21\n",
      "INF partition 2025-10-22\n",
      "INF partition 2025-10-23\n",
      "INF partition 2025-10-24\n",
      "INF partition 2025-10-25\n",
      "INF partition 2025-10-26\n",
      "INF partition 2025-10-27\n",
      "INF partition 2025-10-28\n",
      "INF partition 2025-10-29\n",
      "INF partition 2025-10-30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import timedelta, datetime\n",
    "from scripts.postgresql import (\n",
    "    postgresql_connection,\n",
    "    dict_to_postgresql_schema,\n",
    "    create_table,\n",
    "    insert_data_batch\n",
    ")\n",
    "from scripts.dataframe import (\n",
    "    read_data_from_dataframe\n",
    ")\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Read data\n",
    "cms_articles_df = pd.read_csv(f\"{data_dir}/cms_articles.csv\")\n",
    "\n",
    "# Create connection\n",
    "connection = postgresql_connection(\n",
    "    db_creds['hostname'], \n",
    "    db_creds['port'], \n",
    "    db_creds['username'], \n",
    "    db_creds['password'], \n",
    "    db_creds['database']\n",
    ")\n",
    "\n",
    "# Generate schema\n",
    "dst_table_schema = dict_to_postgresql_schema(json.loads(cms_articles_df.iloc[0].to_json()))\n",
    "\n",
    "# Based on min max date in publish_timestamp\n",
    "start = pd.to_datetime(cms_articles_df['publish_timestamp'].min())\n",
    "end = pd.to_datetime(cms_articles_df['publish_timestamp'].max())\n",
    "\n",
    "current = start\n",
    "while current < end:\n",
    "    print(f\"INF partition {current.strftime('%Y-%m-%d')}\")\n",
    "    # Get data by partition\n",
    "    data_partition_day = read_data_from_dataframe(cms_articles_df, current, timestamp_key_name='publish_timestamp')\n",
    "    # Create table\n",
    "    create_table(connection, 'bronze', 'cms_articles', data_partition_day[0])\n",
    "    # Insert data\n",
    "    insert_data_batch(\n",
    "        connection, \n",
    "        data_partition_day, \n",
    "        'bronze', \n",
    "        'cms_articles', \n",
    "        dst_table_schema,\n",
    "        '_hashrow'\n",
    "    )\n",
    "    current += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc3621",
   "metadata": {},
   "source": [
    "# Study Case 1: GA4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906de66",
   "metadata": {},
   "source": [
    "## Insert Raw Data to Staging Area / Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f558368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF partition 2025-10-01\n",
      "INF partition 2025-10-02\n",
      "INF partition 2025-10-03\n",
      "INF partition 2025-10-04\n",
      "INF partition 2025-10-05\n",
      "INF partition 2025-10-06\n",
      "INF partition 2025-10-07\n",
      "INF partition 2025-10-08\n",
      "INF partition 2025-10-09\n",
      "INF partition 2025-10-10\n",
      "INF partition 2025-10-11\n",
      "INF partition 2025-10-12\n",
      "INF partition 2025-10-13\n",
      "INF partition 2025-10-14\n",
      "INF partition 2025-10-15\n",
      "INF partition 2025-10-16\n",
      "INF partition 2025-10-17\n",
      "INF partition 2025-10-18\n",
      "INF partition 2025-10-19\n",
      "INF partition 2025-10-20\n",
      "INF partition 2025-10-21\n",
      "INF partition 2025-10-22\n",
      "INF partition 2025-10-23\n",
      "INF partition 2025-10-24\n",
      "INF partition 2025-10-25\n",
      "INF partition 2025-10-26\n",
      "INF partition 2025-10-27\n",
      "INF partition 2025-10-28\n",
      "INF partition 2025-10-29\n",
      "INF partition 2025-10-30\n",
      "INF partition 2025-10-31\n",
      "INF partition 2025-11-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import timedelta\n",
    "from scripts.postgresql import (\n",
    "    postgresql_connection,\n",
    "    dict_to_postgresql_schema,\n",
    "    create_table,\n",
    "    insert_data_batch\n",
    ")\n",
    "from scripts.dataframe import (\n",
    "    read_data_from_dataframe\n",
    ")\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Read source data\n",
    "ga4_events_df = pd.read_csv(f\"{data_dir}/ga4_events.csv\")\n",
    "\n",
    "# Create connection\n",
    "connection = postgresql_connection(\n",
    "    db_creds['hostname'], \n",
    "    db_creds['port'], \n",
    "    db_creds['username'], \n",
    "    db_creds['password'], \n",
    "    db_creds['database']\n",
    ")\n",
    "\n",
    "# Generate schema\n",
    "dst_table_schema = dict_to_postgresql_schema(json.loads(ga4_events_df.iloc[0].to_json()))\n",
    "\n",
    "# Based on min max date in event_timestamp\n",
    "start = pd.to_datetime(ga4_events_df['event_timestamp'].min())\n",
    "end = pd.to_datetime(ga4_events_df['event_timestamp'].max())\n",
    "\n",
    "current = start\n",
    "while current < end:\n",
    "    print(f\"INF partition {current.strftime('%Y-%m-%d')}\")\n",
    "    # Get data by partition\n",
    "    data_partition_day = read_data_from_dataframe(ga4_events_df, current, timestamp_key_name='event_timestamp')\n",
    "    # Create table\n",
    "    create_table(connection, 'bronze', 'ga4', data_partition_day[0])\n",
    "    # Insert data\n",
    "    insert_data_batch(\n",
    "        connection, \n",
    "        data_partition_day, \n",
    "        'bronze', \n",
    "        'ga4', \n",
    "        dst_table_schema,\n",
    "        '_hashrow'\n",
    "    )\n",
    "    current += timedelta(days=1)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b621d15",
   "metadata": {},
   "source": [
    "## Generate Daily Mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4670eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF generate ga4 daily mart ... [done]\n"
     ]
    }
   ],
   "source": [
    "from scripts.postgresql import (\n",
    "    postgresql_connection,\n",
    "    create_table,\n",
    "    execute_query\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "ga4_daily_summary_schema = {\n",
    "    'event_timestamp': datetime(2025, 10, 1).date(), \n",
    "    'content_id': 1000, \n",
    "    'cnt_pageviews': 1000.0, \n",
    "    'cnt_session': 1000.0,\n",
    "    'cnt_user_engagment': 1000.0\n",
    "}\n",
    "\n",
    "print(\"INF generate ga4 daily mart ...\", end='')\n",
    "# Create connection\n",
    "connection = postgresql_connection(\n",
    "    db_creds['hostname'], \n",
    "    db_creds['port'], \n",
    "    db_creds['username'], \n",
    "    db_creds['password'], \n",
    "    db_creds['database']\n",
    ")\n",
    "create_table(connection, 'gold', 'ga4_daily_summary', ga4_daily_summary_schema)\n",
    "with open('sql/gold_ga4_daily_summary.sql', 'r') as file:\n",
    "    f = file.read()\n",
    "execute_query(connection, f)\n",
    "connection.close()\n",
    "print(\" [done]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef397d19",
   "metadata": {},
   "source": [
    "# Case Study 2: GAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611fe810",
   "metadata": {},
   "source": [
    "## Insert Raw Data to Staging Area / Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ccb7643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF partition 2025-10-01\n",
      "INF partition 2025-10-02\n",
      "INF partition 2025-10-03\n",
      "INF partition 2025-10-04\n",
      "INF partition 2025-10-05\n",
      "INF partition 2025-10-06\n",
      "INF partition 2025-10-07\n",
      "INF partition 2025-10-08\n",
      "INF partition 2025-10-09\n",
      "INF partition 2025-10-10\n",
      "INF partition 2025-10-11\n",
      "INF partition 2025-10-12\n",
      "INF partition 2025-10-13\n",
      "INF partition 2025-10-14\n",
      "INF partition 2025-10-15\n",
      "INF partition 2025-10-16\n",
      "INF partition 2025-10-17\n",
      "INF partition 2025-10-18\n",
      "INF partition 2025-10-19\n",
      "INF partition 2025-10-20\n",
      "INF partition 2025-10-21\n",
      "INF partition 2025-10-22\n",
      "INF partition 2025-10-23\n",
      "INF partition 2025-10-24\n",
      "INF partition 2025-10-25\n",
      "INF partition 2025-10-26\n",
      "INF partition 2025-10-27\n",
      "INF partition 2025-10-28\n",
      "INF partition 2025-10-29\n",
      "INF partition 2025-10-30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import timedelta\n",
    "from scripts.postgresql import (\n",
    "    postgresql_connection,\n",
    "    dict_to_postgresql_schema,\n",
    "    create_table,\n",
    "    insert_data_batch\n",
    ")\n",
    "from scripts.dataframe import (\n",
    "    read_data_from_dataframe\n",
    ")\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Read data\n",
    "gam_events_df = pd.read_csv(f\"{data_dir}/gam_delivery.csv\")\n",
    "\n",
    "# Create connection\n",
    "connection = postgresql_connection(\n",
    "    db_creds['hostname'], \n",
    "    db_creds['port'], \n",
    "    db_creds['username'], \n",
    "    db_creds['password'], \n",
    "    db_creds['database']\n",
    ")\n",
    "\n",
    "# Generate schema\n",
    "dst_table_schema = dict_to_postgresql_schema(json.loads(gam_events_df.iloc[0].to_json()))\n",
    "\n",
    "# Based on min max date in publish_timestamp\n",
    "start = pd.to_datetime(gam_events_df['served_at'].min())\n",
    "end = pd.to_datetime(gam_events_df['served_at'].max())\n",
    "\n",
    "current = start\n",
    "while current < end:\n",
    "    print(f\"INF partition {current.strftime('%Y-%m-%d')}\")\n",
    "    # Get data by partition\n",
    "    data_partition_day = read_data_from_dataframe(gam_events_df, current, timestamp_key_name='served_at')\n",
    "    # Create table\n",
    "    create_table(connection, 'bronze', 'gam_delivery', data_partition_day[0])\n",
    "    # Insert data\n",
    "    insert_data_batch(\n",
    "        connection, \n",
    "        data_partition_day, \n",
    "        'bronze', \n",
    "        'gam_delivery', \n",
    "        dst_table_schema,\n",
    "        '_hashrow', \n",
    "        ['served_at', 'site', 'ad_unit', 'creative', 'content_id']\n",
    "    )\n",
    "    current += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af3bdde",
   "metadata": {},
   "source": [
    "## Generate Daily Mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211ccea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF generate gam daily mart ... [done]\n"
     ]
    }
   ],
   "source": [
    "from scripts.postgresql import (\n",
    "    postgresql_connection,\n",
    "    create_table,\n",
    "    execute_query\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "gam_daily_summary_schema = {\n",
    "    'served_at': datetime(2025, 10, 1).date(), \n",
    "    'content_id': 1000, \n",
    "    'sum_impressions': 1000.0, \n",
    "    'sum_clicks': 1000.0,\n",
    "    'sum_revenue_usd': 1000.0\n",
    "}\n",
    "\n",
    "print(\"INF generate gam daily mart ...\", end='')\n",
    "# Create connection\n",
    "connection = postgresql_connection(\n",
    "    db_creds['hostname'], \n",
    "    db_creds['port'], \n",
    "    db_creds['username'], \n",
    "    db_creds['password'], \n",
    "    db_creds['database']\n",
    ")\n",
    "create_table(connection, 'gold', 'gam_daily_summary', gam_daily_summary_schema)\n",
    "with open('sql/gold_gam_daily_summary.sql', 'r') as file:\n",
    "    f = file.read()\n",
    "execute_query(connection, f)\n",
    "connection.close()\n",
    "print(\" [done]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d291bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INF create view daily summary ... [done]\n"
     ]
    }
   ],
   "source": [
    "from scripts.postgresql import (\n",
    "    postgresql_connection,\n",
    "    execute_query\n",
    ")\n",
    "\n",
    "print(\"INF create view daily summary ...\", end='')\n",
    "# Create connection\n",
    "connection = postgresql_connection(\n",
    "    db_creds['hostname'], \n",
    "    db_creds['port'], \n",
    "    db_creds['username'], \n",
    "    db_creds['password'], \n",
    "    db_creds['database']\n",
    ")\n",
    "with open('sql/gold_daily_summary.sql', 'r') as file:\n",
    "    f = file.read()\n",
    "execute_query(connection, f)\n",
    "connection.close()\n",
    "print(\" [done]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
